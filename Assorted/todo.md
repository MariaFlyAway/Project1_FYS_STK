## Project 1

### a)
- Generate data from
- Implement Franke function with noise
- Write code for OLS up to fifth order - calculate MSE and R2
- Center and split data - discussion of how, why/why not for scaling
- Plot MSE and R2 
- Plot $\beta$-parameters - comment

### b)

- Implement Ridge method with Franke function
- Perform same analysis as above with different $\lambda$-values - study dependence
- Compare with a

### c)

- Implement Lasso method
- iterate over different lambda values
- note the intercept - scikit excludes
- discuss the three models and which fits the data best

### d)

- Derive the expected value and variance - done, needs explanations
- Part of theory section 

### e)

- make fig 2.11 Hastie
- derive bias-variance tradeoff formula - include in theory-section
- explain what the terms mean and discuss their interpretations
- Perform a bias-variance analysis of the Franke by studying the MSE value as a function of the model complexity
and the number of datapoints and 
- bootstrap-implementation - used for analysis and discussion

### f)

- implement k-fold cross validation - scikit-learn - 5-10 folds
- evaluate the MSE function resulting from the test folds
- compare the MSE from cross-validation to MSE from bootstrap, comment results
- Ridge, Lasso and OLS

### g)

- download data
- prepare inputs to code


### Priorities

Finish a-c so that we can continue working on the other tasks